{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constanst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "N_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './content/DataSet2/Denoising'\n",
    "\n",
    "gaussian_dir = os.path.join(base_dir, 'Gaussian')\n",
    "gaussian_train_dir = os.path.join(gaussian_dir, 'Train')\n",
    "gaussian_test_dir = os.path.join(gaussian_dir, 'Test')\n",
    "gaussian_val_dir = os.path.join(gaussian_dir, 'Validation')\n",
    "\n",
    "periodic_dir = os.path.join(base_dir, 'Periodic')\n",
    "Periodic_train_dir = os.path.join(periodic_dir, 'Train')\n",
    "Periodic_test_dir = os.path.join(periodic_dir, 'Test')\n",
    "Periodic_val_dir = os.path.join(periodic_dir, 'Validation')\n",
    "\n",
    "salt_dir = os.path.join(base_dir, 'Salt')\n",
    "Salt_train_dir = os.path.join(salt_dir, 'Train')\n",
    "Salt_test_dir = os.path.join(salt_dir, 'Test')\n",
    "Salt_val_dir = os.path.join(salt_dir, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('./content/Labels.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder_path):\n",
    "    arr = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            if(N_CHANNELS==1):\n",
    "                arr.append(cv2.imread(file_path,cv2.IMREAD_GRAYSCALE))\n",
    "            else:\n",
    "                arr.append(cv2.imread(file_path))\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_transform(image):\n",
    "    \n",
    "    if(N_CHANNELS==3):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    signal = np.fft.fftshift(np.fft.fft2(image))\n",
    "    # image = 20*(np.log(np.abs(signal)))\n",
    "\n",
    "    # image = (image / np.max(image))*255\n",
    "    # image = cv2.cvtColor(np.uint8(np.round(image)), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_fourier_transform(signal):\n",
    "    image = np.fft.ifft2(np.fft.ifftshift(signal))\n",
    "\n",
    "    if(N_CHANNELS==3):\n",
    "        image = (image / np.max(image))*255\n",
    "        image = cv2.cvtColor(np.uint8(np.round(image)), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = read_images(os.path.join(Periodic_train_dir, 'With-Noise'))\n",
    "# y_train = read_images(os.path.join(Periodic_train_dir, 'Without-Noise'))\n",
    "\n",
    "# X_test = read_images(os.path.join(Periodic_test_dir, 'With-Noise'))\n",
    "# y_test = read_images(os.path.join(Periodic_test_dir, 'Without-Noise'))\n",
    "\n",
    "# X_val = read_images(os.path.join(Periodic_val_dir, 'With-Noise'))\n",
    "# y_val = read_images(os.path.join(Periodic_val_dir, 'Without-Noise'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    # preprocessing_function = fourier_transform,\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    # preprocessing_function = fourier_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow_from_directory(\n",
    "    Periodic_train_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    Periodic_val_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    Periodic_test_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(IMAGE_HEIGHT,IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Define callbacks for early stopping, model checkpointing, and learning rate reduction\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, Input\n",
    "from keras.models import Model\n",
    "\n",
    "def unet_model():\n",
    "  inputs = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS))\n",
    "\n",
    "  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "  pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "  conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
    "  pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "  conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
    "  pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "  conv4 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool3)\n",
    "  pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "  up1 = UpSampling2D((2, 2))(conv4)\n",
    "  conv5 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(up1)\n",
    "  up2 = UpSampling2D((2, 2))(conv5)\n",
    "  conv6 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(up2)\n",
    "  up3 = UpSampling2D((2, 2))(conv6)\n",
    "  conv7 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(up3)\n",
    "  up4 = UpSampling2D((2, 2))(conv7)\n",
    "  conv8 = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(up4)\n",
    "\n",
    "  outputs = Conv2D(N_CHANNELS, (1, 1), activation='sigmoid')(conv8)\n",
    "\n",
    "  return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 0\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=5,\n",
    "        callbacks=my_callbacks,\n",
    "        validation_data=val_gen,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_image = ...\n",
    "fourier_image = fourier_transform(noisy_image)\n",
    "predicted_fourier_image = model.predict(fourier_image)\n",
    "denoised_image = inverse_fourier_transform(predicted_fourier_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ComplexConv2D(tf.keras.layers.Layer):\n",
    "  def __init__(self, filters, kernel_size, activation='relu', **kwargs):\n",
    "    super(ComplexConv2D, self).__init__(**kwargs)\n",
    "    self.filters = filters\n",
    "    self.kernel_size = kernel_size\n",
    "    self.activation = activation\n",
    "    # Initialize real and imaginary weights separately\n",
    "    self.real_conv = tf.keras.layers.Conv2D(filters, kernel_size, activation=activation)\n",
    "    self.imag_conv = tf.keras.layers.Conv2D(filters, kernel_size, activation=activation)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Separate real and imaginary parts\n",
    "    real_input, imag_input = tf.split(inputs, axis=-1, num_or_size_splits=2)\n",
    "    # Apply convolutions separately\n",
    "    real_output = self.real_conv(real_input)\n",
    "    imag_output = self.imag_conv(imag_input)\n",
    "    # Combine real and imaginary parts\n",
    "    output = tf.complex(real_output, imag_output)\n",
    "    return output\n",
    "\n",
    "class ComplexConv2DTranspose(tf.keras.layers.Layer):\n",
    "  def __init__(self, filters, kernel_size, strides=(2, 2), padding='same', activation='relu', **kwargs):\n",
    "    super(ComplexConv2DTranspose, self).__init__(**kwargs)\n",
    "    self.filters = filters\n",
    "    self.kernel_size = kernel_size\n",
    "    self.strides = strides\n",
    "    self.padding = padding\n",
    "    self.activation = activation\n",
    "    # Initialize real and imaginary transposed convolutions separately\n",
    "    self.real_conv_t = tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides, padding, activation=activation)\n",
    "    self.imag_conv_t = tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides, padding, activation=activation)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Separate real and imaginary parts\n",
    "    real_input, imag_input = tf.split(inputs, axis=-1, num_or_size_splits=2)\n",
    "    # Apply transposed convolutions separately\n",
    "    real_output = self.real_conv_t(real_input)\n",
    "    imag_output = self.imag_conv_t(imag_input)\n",
    "    # Combine real and imaginary parts\n",
    "    output = tf.complex(real_output, imag_output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, MaxPooling2D, UpSampling2D\n",
    "\n",
    "def celu(x, alpha=1.0):\n",
    "  return alpha * (tf.math.exp(x) - 1)\n",
    "\n",
    "# Model with complex-valued layers\n",
    "def unet_model():\n",
    "  inputs = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 2))  # Input with 2 channels (real and imaginary)\n",
    "\n",
    "  # Encoder with complex-valued convolutions\n",
    "  conv1 = ComplexConv2D(32, (3, 3), activation=celu)(inputs)\n",
    "  pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "  conv2 = ComplexConv2D(32, (3, 3), activation=celu)(pool1)\n",
    "  pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "  conv3 = ComplexConv2D(32, (3, 3), activation=celu)(pool2)\n",
    "  pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "  conv4 = ComplexConv2D(32, (3, 3), activation=celu)(pool3)\n",
    "  pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "  # Decoder with complex-valued transposed convolutions\n",
    "  up1 = UpSampling2D((2, 2))(pool4)\n",
    "  conv5 = ComplexConv2DTranspose(32, (3, 3), activation=celu)(up1)\n",
    "  up2 = UpSampling2D((2, 2))(conv5)\n",
    "  conv6 = ComplexConv2DTranspose(32, (3, 3), activation=celu)(up2)\n",
    "  up3 = UpSampling2D((2, 2))(conv6)\n",
    "  conv7 = ComplexConv2DTranspose(32, (3, 3), activation=celu)(up3)\n",
    "  up4 = UpSampling2D((2, 2))(conv7)\n",
    "  conv8 = ComplexConv2DTranspose(32, (3, 3), activation=celu)(up4)\n",
    "\n",
    "  # Output with 2 channels (real and imaginary)\n",
    "  outputs = ComplexConv2D(2, (1, 1), activation='linear')(conv8)\n",
    "\n",
    "  return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(metrics=['accuracy'], optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
